# SPDX-License-Identifier: AGPL-3.0-only
# SPDX-FileCopyrightText: 2024 Univention GmbH

---
include:
  - project: "univention/customers/dataport/upx/common-ci"
    ref: "v1.34.0"
    file:
      - "defaults/nubus-workflow.yaml"


stages:
  - prepare
  - deploy
  - test
  - cleanup

.check-variables:
  before_script:
    # kubernets has a 63 chars limit for namespaces so make sure we do not exceed this
    - export DEPLOY_NAMESPACE="${DEPLOY_NAMESPACE:0:63}"
    # urllib (idna) has a char limit of 63 and some tests add -maildev to the url
    # so limit chars ro 63 - 8
    - export DEPLOY_SUBDOMAIN="${DEPLOY_SUBDOMAIN:0:55}"

pipline-configuration:
  stage: prepare
  extends: .check-variables
  script:
    - echo "${DEPLOY_NAMESPACE}"
    - echo "${DEPLOY_SUBDOMAIN}"
    - echo "${RELEASE_VERSION}"
    - echo "${SEMANTIC_VERSION}"
    - echo "${TESTRUNNER_VERSION}"
  variables:
    GIT_STRATEGY: none


deploy-gaia:
  stage: "deploy"
  extends: .check-variables
  image: "ghcr.io/helmfile/helmfile:v0.167.1\
          @sha256:414cb074a0da0f457129590c39d96575fbdcdb7ce75bf0d2b30f05e835947d76"
  script:
    # Prepare
    - export CHART_VERSION=${RELEASE_VERSION}
    - export REVIEW_PREFIX=${DEPLOY_SUBDOMAIN}

    # Ensure cleanup
    - >
      kubectl delete namespace "${DEPLOY_NAMESPACE}"
      --wait
      --timeout=600s
      --ignore-not-found

    # Deploy via ci/helmfile
    - pushd ci
    # TODO: There is an issue around the call to "helm diff". Using "apply"
    # would be preferred since it gives a nice diff of the changes.
    #
    # See: https://github.com/databus23/helm-diff/issues/460
    - helmfile --debug -n "${DEPLOY_NAMESPACE}" sync
    - popd
  environment:
    name: ${CI_COMMIT_REF_SLUG}/nubus-with-extensions
    url: https://${DEPLOY_SUBDOMAIN}.portal.review.univention.dev
    on_stop: stop-deployment
    auto_stop_in: 3 hours
    deployment_tier: development
  resource_group: gaia-${DEPLOY_NAMESPACE}
  artifacts:
    reports:
      dotenv: deploy.env


wait-for-bootstrap:
  stage: deploy
  extends: .check-variables
  image: "ghcr.io/helmfile/helmfile:v0.167.1\
          @sha256:414cb074a0da0f457129590c39d96575fbdcdb7ce75bf0d2b30f05e835947d76"
  needs:
    - deploy-gaia
  script:
    # portal-tiles depend on portal-consumer depends on provisioning-register-consumers depends on stack-data-ums.
    # the portal-consumer and the portal-tiles are up seconds after the provisioning-register-consumers job is done.
    # It's easier to wait for a job than a container, that's why we wait for the portal-tiles a bit more implicitly.
    - echo "Waiting for the bootstrapping of the deployment to finish"
    - echo "Waiting for the creation of the provisioning subscriptions"
    - kubectl -n "${DEPLOY_NAMESPACE}" wait --for=condition=complete jobs.batch "${RELEASE_NAME:=nubus}-provisioning-register-consumers-1" --timeout 10m


configure-tests:
  stage: test
  extends: .check-variables
  image: "ghcr.io/helmfile/helmfile:v0.167.1\
          @sha256:414cb074a0da0f457129590c39d96575fbdcdb7ce75bf0d2b30f05e835947d76"
  script:
    # Grab the e2e-tests sources to use the discovery script
    - "[ ! -e e2e-tests ]"
    - >
      git clone
      --depth 1
      --branch "${TESTRUNNER_CONFIGURATION_BRANCH}"
      https://git.knut.univention.de/univention/customers/dataport/upx/e2e-tests.git

    # Grab the pytest configuration
    - pushd ./e2e-tests
    - source ./discover-env-from-cluster.sh
    - popd
    - echo "PYTEST_ADDOPTS=$PYTEST_ADDOPTS" > deploy.env
  artifacts:
    reports:
      dotenv: deploy.env
  variables:
    TESTRUNNER_CONFIGURATION_BRANCH: main


e2e-tests:
  stage: test
  extends: .check-variables
  needs:
    - configure-tests
  image: "gitregistry.knut.univention.de/univention/customers/dataport/upx/\
          e2e-tests/e2e-tests-runner:${TESTRUNNER_VERSION}"
  script:
    - pushd /e2e
    - >
      pytest
      -m acceptance_environment
      --showlocals
      --junitxml=test_results.xml
      --html=report.html
      --self-contained-html
      --verbose
      --video=retain-on-failure
      --tracing=retain-on-failure
      --screenshot=only-on-failure
      || exit_code=$?
    - popd
    # NOTE: This is a workaround. Our testrunner image does not yet support to
    # run the tests in a different directory than "/e2e". So we copy the reports
    # back into the CI_PROJECT_DIR for Gitlab to accept them as artifacts.
    - mkdir -p /e2e/test-results
    - cp -a /e2e/test-results .
    - cp -a /e2e/report.html .
    - cp -a /e2e/test_results.xml .
    - exit $exit_code
  artifacts:
    expose_as: "report"
    paths:
      - "${CI_PROJECT_DIR}/report.html"
      - "${CI_PROJECT_DIR}/test_results.xml"
      - "${CI_PROJECT_DIR}/test-results/"
    when: "always"
    reports:
      junit: "test_results.xml"
    expire_in: "1 week"
  tags:
    - "docker"


stop-deployment:
  stage: cleanup
  extends: .check-variables
  allow_failure: true
  needs:
    - deploy-gaia
  image: "ghcr.io/helmfile/helmfile:v0.167.1\
          @sha256:414cb074a0da0f457129590c39d96575fbdcdb7ce75bf0d2b30f05e835947d76"
  script:
    - >
      kubectl delete namespace "${DEPLOY_NAMESPACE}"
      --wait
      --timeout=600s
      --ignore-not-found
  variables:
    GIT_STRATEGY: none
  environment:
    name: ${CI_COMMIT_REF_SLUG}/nubus-with-extensions
    action: stop
  rules:
    - when: manual


cleanup-failed-deployment:
  extends: stop-deployment
  rules:
    - when: on_failure
